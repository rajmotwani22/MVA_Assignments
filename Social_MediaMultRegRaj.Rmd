---
title: "Social_Media_MultipleRegression"
author: "Raj Motwani"
date: "2024-04-09"
output: html_document
---

```{r cars}
lay_data <- read.csv("/Users/raj//Downloads/social1.csv", row.names=1)

str(lay_data)

colnames(lay_data) <- c("Instagram", "LinkedIn", "Snapchat", "Twitter", "Whatsapp", "Youtube", "OTT", "Reddit", "Trouble_sleep", "Mood", "Tired_morning")


fit <- lm(Trouble_sleep~Instagram + Snapchat + Twitter, data=lay_data) 
# In linear regression, the assumption is a linear relationship between variables. The model predicts the dependent variable (mpg) using several independent variables. Residuals are the differences between actual and predicted values. The median of these residuals gives the median error, showing how well the model predicts mpg across the dataset.


#show the results
summary(fit)


fit <- lm(Trouble_sleep~Instagram + Snapchat + Twitter, data=lay_data)#removed the values that were 0.05
# Useful Helper Functions
coefficients(fit)
library(GGally)
ggpairs(data=lay_data, title="Social media Data")
confint(fit,level=0.95)#confidence interval
fitted(fit)

residuals(fit)
#Anova Table
anova(fit)
vcov(fit)
cov2cor(vcov(fit))
temp <- influence.measures(fit)#get to know abt outliers of data - makes * at the end
temp
plot(fit)

library(car)
outlierTest(fit)#current one shows outlier 
leveragePlots(fit) # leverage plots
# Influential Observations
# added variable plots
avPlots(fit)
# Cook's D plot
# identify D values > 4/(n-k-1)
cutoff <- 4/((nrow(lay_data)-length(fit$coefficients)-2))
plot(fit, which=4, cook.levels=cutoff)
# Influence Plot
influencePlot(fit, id.method="identify", main="Influence Plot", sub="Circle size is proportial to Cook's Distance" )
# Normality of Residuals
# qq plot for studentized resid
qqPlot(fit, main="QQ Plot")


library(MASS)
sresid <- studres(fit)
hist(sresid, freq=FALSE, main="Distribution of Studentized Residuals")
xfit<-seq(min(sresid),max(sresid),length=40)
yfit<-dnorm(xfit)
lines(xfit, yfit)
#Non-constant Error Variance
# Evaluate homoscedasticity
# non-constant error variance test
ncvTest(fit)
# plot studentized residuals vs. fitted values
spreadLevelPlot(fit)
#Multi-collinearity
# Evaluate Collinearity
vif(fit) # variance inflation factors
sqrt(vif(fit)) > 2 # problem?
#Nonlinearity
# component + residual plot
crPlots(fit)
# Ceres plots
ceresPlots(fit)
#Non-independence of Errors
# Test for Autocorrelated Errors
durbinWatsonTest(fit)

```

# MODEL ACCURACY

```{r }
library(gvlma)
gvmodel <- gvlma(fit)
summary(gvmodel)
fit
summary(fit)
fit1 <- fit
fit2 <- lm(Trouble_sleep~Instagram + Snapchat + Twitter, data = lay_data)
# compare models
anova(fit1, fit2)
step <- stepAIC(fit, direction="both")
step$anova # display results
library(leaps)
leaps<-regsubsets(Trouble_sleep~Instagram + Snapchat + Twitter,data=lay_data,nbest=10)
# view results
plot(leaps)
plot(leaps,scale="r2")
plot(leaps,scale="bic")
summary(leaps)
#Insights:The comparison between Model 1 and Model 2 indicates that whether the variables Instagram, Snapchat, and Twitter are included or excluded, it doesn't significantly affect the model's capacity to account for the variability in Trouble_sleep.
```




# MODEL PREDICTION

```{r }
library(relaimpo)
calc.relimp(fit,type=c("lmg","last","first","pratt"),
            rela=TRUE)
# Bootstrap Measures of Relative Importance (1000 samples)
boot <- boot.relimp(fit, b = 1000, type = c("lmg",
                                            "last", "first", "pratt"), rank = TRUE,
                    diff = TRUE, rela = TRUE)
booteval.relimp(boot) # print result
plot(booteval.relimp(boot,sort=TRUE)) # plot result
#https://rpubs.com/davoodastaraky/mtRegression
summary(fit)
predict.lm(fit, data.frame(Instagram =0.2 ,Snapchat=0.1,Twitter=0.5) )



```
Insights:
The model predicts that Trouble_sleep will be around 0.2391868 when Instagram has a value of 0.2, Snapchat has a value of 0.1, and Twitter has a value of 0.5.

